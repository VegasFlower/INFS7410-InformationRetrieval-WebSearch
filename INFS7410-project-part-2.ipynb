{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d4ae85d",
   "metadata": {},
   "source": [
    "# INFS7410 Project - Part 2\n",
    "\n",
    "_version 1.0_\n",
    "\n",
    "### Preamble\n",
    "\n",
    "The due date for this assignment is **28 October 2021 16:00 Eastern Australia Standard Time**.\n",
    "\n",
    "This part of the project is worth 20% of the overall mark for INFS7410 (part 1 + part 2 = 40%). A detailed marking sheet for this assignment is provided alongside this notebook. The project is to be completed individually. \n",
    "\n",
    "We recommend that you make an early start on this assignment and proceed by steps. There are several activities you may have already tackled, including setting up the pipeline, manipulating the queries, implement some retrieval functions, and performing evaluation and analysis. Most of the assignment relies on knowledge and code you should have already have experienced in the computer practicals; however, there are some hidden challenges here and there that you may require some time to solve.\n",
    "\n",
    "### Aim\n",
    "\n",
    "Project aim: The aim of this project is for you to implement several neural information retrieval methods, evaluate them and compare them in the context of a multi-stage ranking pipeline.\n",
    "\n",
    "The speficic objectives of Part 2 is to:\n",
    "\n",
    "* Setup your infrastructure to index the collection and evaluate queries.\n",
    "* Implement neural information retrieval models (only inference).\n",
    "* Implement multi-stage ranking pipelines, i.e., BM25 + neural rankers.\n",
    "\n",
    "### The Information Retrieval Task: Web Passage Ranking\n",
    "\n",
    "As in part 1 of the project, in part 2 we will consider the problem of open-domain passage ranking in answer to web queries. In this context, users pose queries to the search engine and expect answers in the form of a ranked list of passages (maximum 1000 passages to be retrieved). \n",
    "\n",
    "The provided queries are actual queries submitted to the Microsoft Bing search engine. There are approximately 8.8 million passages in the collection, and the goal is to rank them based on their relevance to the queries.\n",
    "\n",
    "\n",
    "### What we provide you with:\n",
    "\n",
    "#### Files from practical\n",
    "\n",
    "* A collection of 8.8 million text passages extracted from web pages (`collection.tsv`— provided in Week 1).\n",
    "* A query file that contains 43 queries for you to perform retrieval experiments (`queries.tsv`— provided in Week 2).\n",
    "* A qrel file containing relevance judgements to tune your methods (`qrels.txt`— provided in Week 2).\n",
    "* Pytorch model files for ANCE.\n",
    "\n",
    "#### Extra files for this project\n",
    "\n",
    "* A leaderboard system for you to evaluate how well your system performs.\n",
    "* A test query file that contains 54 queries for you to generate run files to submit to the leaderboard (`test_queries.tsv`).\n",
    "* This jupyter notebook, which you will include inside it your implementation and report.\n",
    "* An hdf5 file that contains TILDEv2 pre-computed terms weights for the collection. Download from this [link](https://drive.google.com/file/d/199IO4E2ThiyLkMWokfr3Y9JY3DWSoFLt/view?usp=sharing)\n",
    "\n",
    "Put this notebook and provided files under the same directory.\n",
    "\n",
    "#### What you need to produce\n",
    "\n",
    "You need to produce:\n",
    "\n",
    "* Correct implementations of the methods required by this project specifications.\n",
    "* An explanation of the retrieval methods used, including the formulas that represent the models you implemented and code that implements that formula, an explanation of the evaluation settings followed, and a discussion of the findings. Please refer to the marking sheet to understand how each of these requirements are graded.\n",
    "\n",
    "You are required to produce both of these within this jupyter notebook.\n",
    "\n",
    "#### Required methods to implement\n",
    "\n",
    "In Part 2 of the project, you are required to implement the following retrieval methods. All implementations should be based on your code (except for BM25, where you can use the Pyserini built-in SimpleSearcher).\n",
    "\n",
    "1. Dense Retriever (ANCE): Use ANCE to re-rank BM25 top-k documents. See the practical in Week 10 for background information.\n",
    "2. TILDEv2: Use TILDEv2 to re-rank BM25 top-k documents. See the practical in Week 10 for background information.\n",
    "3. Three-stage ranking pipeline: Use TILDEv2 to re-rank BM25 top-k documents, then use monoBERT to re-rank TILDEv2 top-k documents. See the practical in Week 9 and Week 10 for background information.\n",
    "\n",
    "You can choose an arbitrary number for the choice of cut-off k, but you need to be aware that these neural models are slow to perform inference on the CPU, where a large k might be infeasible. You are free to use Colab, but make sure you copy your code in this notebook.\n",
    "\n",
    "For TILDEv2, unlike what you did in practical, we offer you the pre-computed term weights for the whole collection (for more details, see the `Initial packages and functions` cell). This means you can have a fast re-ranking speed for TILDEv2. Use this advantage to trade-off effectiveness and efficiency for your three-stage ranking pipeline implementation.\n",
    "\n",
    "You should have already attempted many of these implementations above as part of the computer pracs exercises.\n",
    "\n",
    "#### Required evaluation to perform\n",
    "\n",
    "In Part 2 of the project, you are required to perform the following evaluation:\n",
    "\n",
    "1. For all methods, report effectiveness using `queries.tsv` and `qrels.txt` and submit your runs on the `test_queries.tsv` using the parameter values you selected from the `queries.tsv` to the leaderboard system. \n",
    "2. Report every method's effectiveness and efficiency (average query latency) on the `queries.tsv` and the corresponding cut-off k into a table. Perform statistical significance analysis across the results of the methods and report them in the tables.\n",
    "3. Produce a gain-loss plot that compares the most and least effective of the three required methods above in terms of nDCG@10 on `queries.csv`.\n",
    "4. Comment on trends and differences observed when comparing your findings. Is there a method that consistently outperforms the others on the `queries.tsv` and the `test_queries.tsv`?\n",
    "\n",
    "Regarding evaluation measures, evaluate the retrieval methods with respect to nDCG at 10 (`ndcg_cut_10`). You should use this measure as the target measure for tuning. Also compute reciprocal rank at 1000 (`recip_rank`),  MAP (`map`) and Recall at 1000 (`recall_1000`).\n",
    "\n",
    "For all statistical significance analyses, use a paired t-test and distinguish between p<0.05 and p<0.01.\n",
    "\n",
    "#### How to submit\n",
    "\n",
    "You will have to submit one file:\n",
    "\n",
    "1. A zip file containing this notebook (.ipynb) and this notebook **as a PDF document**. The code should be able to be executed by us. Remember to include all your discussion and analysis also in this notebook and not as a separate file.\n",
    "\n",
    "It needs to be submitted via the relevant Turnitin link in the INFS7410 BlackBoard site by **28 October 2021, 16:00 Eastern Australia Standard Time**, unless you have been given an extension (according to UQ policy), *before* the due date of the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7866b31a",
   "metadata": {},
   "source": [
    "## Initial packages and functions\n",
    "----\n",
    "Unlike prac week 10 which we compute contextualized term weights with TILDEv2 in an \"on-the-fly\" manner. In this project, we provide an hdf5 file that contains pre-computed term weights for all the passages in the collection. \n",
    "\n",
    "Frist, pip install the h5py library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb2f55c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /Users/tongzheng/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages (3.5.0)\r\n",
      "Requirement already satisfied: cached-property in /Users/tongzheng/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages (from h5py) (1.5.2)\r\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/tongzheng/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages (from h5py) (1.21.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44c00b7",
   "metadata": {},
   "source": [
    "The following cell gives you an example of how to use the file to access token weights and their corresponding token ids given a document id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aae360f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProxyError",
     "evalue": "HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/added_tokens.json (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1074: The handshake operation timed out')))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_new_proxy_conn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhttp_tunnel_required\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_proxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_prepare_proxy\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mssl_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mtls_in_tls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtls_in_tls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    449\u001b[0m         ssl_sock = _ssl_wrap_socket_impl(\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtls_in_tls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m    869\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mtimeout\u001b[0m: _ssl.c:1074: The handshake operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    755\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 756\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/added_tokens.json (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1074: The handshake operation timed out')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProxyError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8e811444ae1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtoken_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdocid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{tokenizer.decode([token_id])}: {weight}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1678\u001b[0m                         \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m                         \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1680\u001b[0;31m                         \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1681\u001b[0m                     )\n\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1277\u001b[0m             \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m         )\n\u001b[1;32m   1281\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0metag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X-Linked-Etag\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ETag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'head'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infs7410/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ProxyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mProxyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SSLError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProxyError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/added_tokens.json (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1074: The handshake operation timed out')))"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from transformers import BertTokenizer\n",
    "f = h5py.File(\"tildev2_weights.hdf5\", 'r')\n",
    "weights_file = f['documents'][:]  # load the hdf5 file to the memory.\n",
    "\n",
    "docid = 0\n",
    "token_weights, token_ids = weights_file[docid]\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "for token_id, weight in zip(token_ids.tolist(), token_weights):\n",
    "    print(f\"{tokenizer.decode([token_id])}: {weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5fa67e",
   "metadata": {},
   "source": [
    "Note, these token_ids include stopwords' ids, remember to remove stopwords' ids for query tokens.\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7acc8bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all your python libraries and put setup code here.\n",
    "from pyserini.search import SimpleSearcher\n",
    "from pyserini.analysis import Analyzer, get_lucene_analyzer\n",
    "from pyserini.index import IndexReader\n",
    "from collections import Counter\n",
    "import json\n",
    "import numpy as np\n",
    "from modeling import AnceModel\n",
    "from transformers import AutoTokenizer\n",
    "from modeling import TILDEv2\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pytrec_eval\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cpu'\n",
    "ance_model = AnceModel.from_pretrained('ANCE_Model').eval()\n",
    "ance_model.to(device)\n",
    "ance_tokenizer = AutoTokenizer.from_pretrained('ANCE_Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741aed2",
   "metadata": {},
   "source": [
    "Open and readin queries file, implement basic search method,\n",
    "the method uses bm25 as scorer. k is set to 1000, which means\n",
    "that it will try to find top 1000 documents that might be\n",
    "relevant with the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1a981316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your implementation of methods here.\n",
    "# bm25\n",
    "searcher = SimpleSearcher('indexes/lucene-index-msmarco-passage-noProcessing/')\n",
    "searcher.set_analyzer(get_lucene_analyzer(stemming=False, stopwords=False))\n",
    "\n",
    "lucene_analyzer = get_lucene_analyzer(stemming=False, stopwords=False)\n",
    "analyzer = Analyzer(lucene_analyzer)\n",
    "searcher = SimpleSearcher('indexes/lucene-index-msmarco-passage-vectors-noProcessing/')\n",
    "searcher.set_analyzer(lucene_analyzer)\n",
    "\n",
    "index_reader = IndexReader('indexes/lucene-index-msmarco-passage-vectors-noProcessing/')\n",
    "\n",
    "# set up queries\n",
    "queries = []\n",
    "with open(\"queries.tsv\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        parts = line.split(\"\\t\")\n",
    "        # parts[0] ~> topic id\n",
    "        # parts[1] ~> query\n",
    "        queries.append((parts[0], parts[1].strip()))\n",
    "\n",
    "def search(run_file: str, k: int=10):\n",
    "    total = []\n",
    "    with open(run_file, \"w\") as f:\n",
    "        for topic_id, query in queries:\n",
    "            hits = searcher.search(query, k=k)\n",
    "            q_terms = analyzer.analyze(query)\n",
    "            # print(q_terms)\n",
    "            result = []\n",
    "            for i, hit in enumerate(hits):\n",
    "                # Compute the statistics.\n",
    "                tf = index_reader.get_document_vector(hit.docid)\n",
    "                df= {term: (index_reader.get_term_counts(term, analyzer=None))[0] for term in tf.keys()}\n",
    "                doc_len = len(tf)\n",
    "                bm25_score = 0\n",
    "                c = list((Counter(q_terms) & Counter(tf.keys())).elements())\n",
    "                \n",
    "                for term in c:\n",
    "                    bm25_score += index_reader.compute_bm25_term_weight(hit.docid, term, analyzer=None)\n",
    "                content = json.loads(hit.raw)\n",
    "                result.append((hit.docid, bm25_score))\n",
    "            result.sort(key=lambda x:x[1], reverse = True)\n",
    "            total.append(result)\n",
    "                \n",
    "            for i, r in enumerate(sorted(result, key=lambda x: x[1], reverse=True)):\n",
    "                # Write the results to our file.\n",
    "                f.write(f\"{topic_id} Q0 {r[0]} {i} {r[1]} infs7410_project2_bm25\\n\")\n",
    "    return total\n",
    "\n",
    "bm25 = search(\"project2_bm25.run\", k=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6dc513",
   "metadata": {},
   "source": [
    "Implement ANCE model, it uses the result from the basic searcher using bm25.\n",
    "Obtain the top k tuples of each query, calculate the embeddings of the contents\n",
    "and the query itself, using dot product to evaluate two embeddings to see if they\n",
    "are more relevant than others. After the reranking, put the reranking list with\n",
    "the rest of bm25 search result, write into run file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "91e250c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ANCE\n",
    "\n",
    "def ance_encode(text, device='cpu'):\n",
    "    # get query inputs\n",
    "    inputs = ance_tokenizer(\n",
    "            [text],\n",
    "            max_length=64,\n",
    "            padding='longest',\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "    # pass query inputs to device and to model\n",
    "    # use 'cuda:0' if you are using GPU\n",
    "    inputs.to(device)\n",
    "    # compute query embeddings\n",
    "    embeddings = ance_model(inputs[\"input_ids\"]).detach().cpu().numpy().flatten()\n",
    "    return embeddings\n",
    "\n",
    "# obtain embeddings of queries\n",
    "queries_embeddings = []\n",
    "\n",
    "for topic_id, query in queries:\n",
    "    inputs = ance_tokenizer(\n",
    "                [query],\n",
    "                max_length=64,\n",
    "                padding='longest',\n",
    "                truncation=True,\n",
    "                add_special_tokens=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "    query_embeddings = ance_model(inputs[\"input_ids\"]).detach().cpu().numpy().flatten()\n",
    "    queries_embeddings.append((topic_id, query_embeddings))\n",
    "    \n",
    "def re_rank_ance(run_file: str, j: int=10):\n",
    "    with open(run_file, \"w\") as f:\n",
    "        final = []\n",
    "        bm25_top_k = search(\"bm25_top_k.run\", k = j)\n",
    "        index = 0\n",
    "        for query in bm25_top_k:\n",
    "            result = []\n",
    "            for a in range(0, j):\n",
    "                doc = searcher.doc(query[a][0])\n",
    "                json_doc = json.loads(doc.raw())\n",
    "                contents = json_doc[\"contents\"]\n",
    "                \n",
    "                passage_embeddings = ance_encode(contents)\n",
    "                score = np.dot(queries_embeddings[index][1], passage_embeddings)\n",
    "\n",
    "                result.append((json_doc[\"id\"], score))\n",
    "            index = index + 1\n",
    "            result.sort(key=lambda x:x[1], reverse=True)\n",
    "            final.append(result)\n",
    "\n",
    "        cur = 0\n",
    "        for query in queries:\n",
    "            result = []\n",
    "            for x in final[cur]:\n",
    "                result.append(x)\n",
    "            rest = bm25[cur][j:]\n",
    "            for x in rest:\n",
    "                result.append(x)\n",
    "            cur = cur + 1\n",
    "            for i, r in enumerate(result):\n",
    "                f.write(f\"{query[0]} Q0 {r[0]} {i} {r[1]} infs7410_project2_bm25_rerank_ance\\n\")\n",
    "\n",
    "re_rank_ance(\"project2_bm25_ance.run\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38feb90",
   "metadata": {},
   "source": [
    "Implement Tildev2 model, it uses the result from the basic searcher using bm25.\n",
    "Obtain the top k tuples of each query, calculate the embeddings of the contents\n",
    "and the query itself, using tildev2_scoring function to evaluate query and passage\n",
    "to see if they are more relevant than others. After the reranking, put the reranking\n",
    "list with the rest of bm25 search result, write into run file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "fa69bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TILDEv2\n",
    "\n",
    "model = TILDEv2.from_pretrained(\"tildev2-noexp\").eval()\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"tildev2-noexp\")\n",
    "\n",
    "stop_ids = model.get_stop_ids(tokenizer)\n",
    "\n",
    "def tildev2_scoreing(query, document):\n",
    "    # get document term weights\n",
    "    inputs = tokenizer(document, return_tensors='pt')\n",
    "    token_ids, token_weights = model.encode(**inputs)\n",
    "    token_ids = np.array(token_ids)\n",
    "    token_weights = np.array(token_weights)\n",
    "    \n",
    "    # get query token ids\n",
    "    query_ids = tokenizer(query, add_special_tokens=False)[\"input_ids\"]\n",
    "    query_ids = [tok_id for tok_id in query_ids if tok_id not in stop_ids]  # remove stopwords for query\n",
    "    \n",
    "    # use query token ids to match term weights in the document\n",
    "    token_idx = [np.where(token_ids == tok_id) for tok_id in query_ids]\n",
    "    score = 0\n",
    "    for idx in token_idx:\n",
    "        if len(idx[0]) != 0:\n",
    "            score += np.max(token_weights[idx])  # if a query term appears multiple times in the passage, use the max socre\n",
    "    return score\n",
    "\n",
    "def tildev2(run_file: str, j: int=10):\n",
    "    with open(run_file, \"w\") as f:\n",
    "        final = []\n",
    "        bm25_top_k = search(\"bm25_top_k.run\", k = j)\n",
    "        index = 0\n",
    "        for query in bm25_top_k:\n",
    "            result = []\n",
    "            for a in range(0, j):\n",
    "                #print(query[a][0])\n",
    "                doc = searcher.doc(query[a][0])\n",
    "                json_doc = json.loads(doc.raw())\n",
    "                contents = json_doc[\"contents\"]\n",
    "                #print(contents)\n",
    "                score = tildev2_scoreing(queries[index][1], contents)\n",
    "                #print(score)\n",
    "                result.append((json_doc[\"id\"], score))\n",
    "            index = index + 1\n",
    "            result.sort(key=lambda x:x[1], reverse=True)\n",
    "            final.append(result)\n",
    "\n",
    "#         re_ranked = []\n",
    "        cur = 0\n",
    "        for query in queries:\n",
    "            result = []\n",
    "            for x in final[cur]:\n",
    "                result.append(x)\n",
    "            rest = bm25[cur][j:]\n",
    "            for x in rest:\n",
    "                result.append(x)\n",
    "#             print(result)\n",
    "#             re_ranked.append(result)\n",
    "            cur = cur + 1\n",
    "            for i, r in enumerate(result):\n",
    "                # Write the results to our file.\n",
    "                f.write(f\"{query[0]} Q0 {r[0]} {i} {r[1]} infs7410_project2_bm25_rerank_tildev2\\n\")\n",
    "        return final\n",
    "                \n",
    "\n",
    "tildev2_result = tildev2(\"project2_bm25_tildev2.run\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9726f1b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tildev2_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c2a760a20b35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mthree_stage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthree_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"project2_three_stages.run\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-c2a760a20b35>\u001b[0m in \u001b[0;36mthree_stage\u001b[0;34m(run_file, j)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtildev2_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;31m# get the top j tuples of results from tildev2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tildev2_result' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "monoBERT = AutoModelForSequenceClassification.from_pretrained('monobert-large-msmarco', cache_dir=\"./cache\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('monobert-large-msmarco', cache_dir=\"./cache\")\n",
    "\n",
    "def monoBERT_score(query: str, passage: str):\n",
    "    ret = tokenizer.encode_plus(query,\n",
    "                                passage,\n",
    "                                max_length=512,\n",
    "                                truncation=True,\n",
    "                                return_token_type_ids=True,\n",
    "                                return_tensors='pt')\n",
    "    input_ids = ret['input_ids'].to(DEVICE)\n",
    "    tt_ids = ret['token_type_ids'].to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        output, = monoBERT(input_ids, token_type_ids=tt_ids, return_dict=False)\n",
    "        score = torch.nn.functional.softmax(output, 1)[0, -1].cpu().item()\n",
    "    return score\n",
    "\n",
    "def three_stage(run_file: str, j: int=10):\n",
    "    with open(run_file, \"w\") as f:\n",
    "        final = []\n",
    "        index = 0\n",
    "        for query in tildev2_result:\n",
    "            # get the top j tuples of results from tildev2\n",
    "            result = []\n",
    "            for a in range(0, j):\n",
    "                #print(query[a][0])\n",
    "                doc = searcher.doc(query[a][0])\n",
    "                json_doc = json.loads(doc.raw())\n",
    "                contents = json_doc[\"contents\"]\n",
    "                #print(contents)\n",
    "                score = monoBERT_score(queries[index][1], contents)\n",
    "                #print(score)\n",
    "                result.append((json_doc[\"id\"], score))\n",
    "            index = index + 1\n",
    "            result.sort(key=lambda x:x[1], reverse=True)\n",
    "            final.append(result)\n",
    "\n",
    "        length = len(tildev2_result[0])\n",
    "        cur = 0\n",
    "        # append all seperated re-ranked results together\n",
    "        # and write them into run file\n",
    "        for query in queries:\n",
    "            result = []\n",
    "            for x in final[cur]:\n",
    "                result.append(x)\n",
    "#             rest = tildev2_result[cur][j:length]\n",
    "            for x in tildev2_result[cur][j:length]:\n",
    "                result.append(x)\n",
    "            for x in bm25[cur][length:]:\n",
    "                result.append(x)\n",
    "#             print(result)\n",
    "            cur = cur + 1\n",
    "            for i, r in enumerate(result):\n",
    "                f.write(f\"{query[0]} Q0 {r[0]} {i} {r[1]} infs7410_project2_three_stages\\n\")\n",
    "        return final\n",
    "\n",
    "three_stage = three_stage(\"project2_three_stages.run\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9cec0343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map                      all     0.3566\n",
      "recip_rank               all     0.8113\n",
      "ndcg_cut_10              all     0.4853\n",
      "recall_1000              all     0.6881\n",
      "\n",
      "map                      all     0.3671\n",
      "recip_rank               all     0.8549\n",
      "ndcg_cut_10              all     0.5291\n",
      "recall_1000              all     0.6881\n",
      "\n",
      "map                      all     0.3665\n",
      "recip_rank               all     0.8725\n",
      "ndcg_cut_10              all     0.5318\n",
      "recall_1000              all     0.6881\n",
      "\n",
      "map                      all     0.2322\n",
      "recip_rank               all     0.6216\n",
      "ndcg_cut_10              all     0.3344\n",
      "recall_1000              all     0.6881\n"
     ]
    }
   ],
   "source": [
    "# evaluations\n",
    "def print_results(run_file, qrel_file='qrel.txt', measures=[\"map\", \"recip_rank\", \"ndcg_cut_10\", \"recall_1000\"]):        \n",
    "    with open(run_file, \"r\") as f:\n",
    "        run = pytrec_eval.parse_run(f)  \n",
    "    with open(qrel_file, \"r\") as f:\n",
    "        msmarco_qrels = pytrec_eval.parse_qrel(f)\n",
    "    evaluator = pytrec_eval.RelevanceEvaluator(query_relevance=msmarco_qrels, measures=measures)\n",
    "    results = evaluator.evaluate(run)\n",
    "    for measure in measures:\n",
    "        print('{:25s}{:8s}{:.4f}'.format(measure, 'all', pytrec_eval.compute_aggregated_measure(measure,\n",
    "                                  [query_measures[measure]for query_measures in results.values()]))) \n",
    "\n",
    "\n",
    "\n",
    "print_results(\"project2_bm25.run\")\n",
    "print()\n",
    "print_results(\"project2_bm25_ance.run\")\n",
    "print()\n",
    "print_results(\"project2_bm25_tildev2.run\")\n",
    "print()\n",
    "print_results(\"project2_three_stages.run\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2373a2f",
   "metadata": {},
   "source": [
    "|   run(k=10)  \t|   map  \t| racip_rank \t| ndcg_10 \t| recall_1000 \t|\n",
    "|:------------:\t|:------:\t|:----------:\t|:-------:\t|:-----------:\t|\n",
    "|     bm25     \t| 0.3566 \t|   0.8113   \t|  0.4853 \t|    0.6881   \t|\n",
    "|     ance     \t| 0.3671 \t|   0.8549   \t|  0.5291 \t|    0.6881   \t|\n",
    "|    tildev2   \t| 0.3665 \t|   0.8725   \t|  0.5318 \t|    0.6881   \t|\n",
    "| three_stages \t| 0.2322 \t|   0.6216   \t|  0.3344 \t|    0.6881   \t|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e134d997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=-3.9394580374294095, pvalue=0.000302508885891443)\n",
      "Ttest_relResult(statistic=-3.9884972830002465, pvalue=0.0002605599672805988)\n",
      "Ttest_relResult(statistic=3.98408896193045, pvalue=0.0002640871575169761)\n"
     ]
    }
   ],
   "source": [
    "with open(\"project2_bm25.run\", \"r\") as f:\n",
    "    project2_bm25_run = pytrec_eval.parse_run(f)\n",
    "with open(\"project2_bm25_ance.run\", \"r\") as f:\n",
    "    project2_ance_run = pytrec_eval.parse_run(f)\n",
    "with open(\"project2_bm25_tildev2.run\", \"r\") as f:\n",
    "    project2_tildev2_run = pytrec_eval.parse_run(f)\n",
    "with open(\"project2_three_stages.run\", \"r\") as f:\n",
    "    project2_three_stages_run = pytrec_eval.parse_run(f)  \n",
    "    \n",
    "bm25_results = evaluator.evaluate(project2_bm25_run)\n",
    "ance_results = evaluator.evaluate(project2_ance_run)\n",
    "tildev2_results = evaluator.evaluate(project2_tildev2_run)\n",
    "three_stages_results = evaluator.evaluate(project2_three_stages_run)\n",
    "\n",
    "query_ids = list(\n",
    "    set(bm25_results.keys()) & set(acne_results.keys()))\n",
    "\n",
    "bm25_scores = [\n",
    "    bm25_results[query_id][\"ndcg_cut_10\"] for query_id in query_ids]\n",
    "acne_scores = [\n",
    "    acne_results[query_id][\"ndcg_cut_10\"] for query_id in query_ids]    \n",
    "tildev2_scores = [\n",
    "    tildev2_results[query_id][\"ndcg_cut_10\"] for query_id in query_ids]\n",
    "three_stages_scores = [\n",
    "    three_stages_results[query_id][\"ndcg_cut_10\"] for query_id in query_ids]\n",
    "\n",
    "print(scipy.stats.ttest_rel(bm25_scores, acne_scores))\n",
    "print(scipy.stats.ttest_rel(bm25_scores, tildev2_scores))\n",
    "print(scipy.stats.ttest_rel(bm25_scores, three_stages_scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde413e8",
   "metadata": {},
   "source": [
    "From the result of statistical significance, it can be seen that comparing to\n",
    "fundamental bm25, both ANCE and tildev2 provide rather significantly effective\n",
    "models.\n",
    "\n",
    "Furthermore, tildev2 model and ACNE model have rather similar results in terms\n",
    "of the mearsures like map, recip_rank ndcg_cut_10 and recall_1000. Tildev2 might\n",
    "have a slightly better performance than ANCE does. Both two models performs better\n",
    "than the three-stages model which combines them together. Result of three-stages\n",
    "model was not ideal, though having high statistical significance, but performance\n",
    "was much lower. I'm not sure if it was because my implementation gets wrong in\n",
    "some place.\n",
    "\n",
    "Overally, map, recip_rank and ndcg_cut_10 all have been improved after applying\n",
    "ACNE model and tildev2 model individually, improvement of recall_1000 was not\n",
    "quite obvious, it might due to the number of total documents retrieved is kept\n",
    "as 1000. Also, the fundamental searcher using bm25 can be a potential factor. Both\n",
    "cause the total number of top 1000 retrieved relevant documents stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "77a8fb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "measure = \"ndcg_cut_10\"\n",
    "title = \"gains/losses in ndcg_cut_10 between best and worst\"\n",
    "\n",
    "r = dict([(key, value[measure]) for key, value in bm25_results.items()])\n",
    "r1 = dict([(key, value[measure]) for key, value in bm25_results.items()])\n",
    "r2 = dict([(key, value[measure]) for key, value in tildev2_results.items()])\n",
    "ind = np.arange(len(r1))\n",
    "# https://matplotlib.org/3.1.0/gallery/lines_bars_and_markers/barchart.html\n",
    "plt.bar(ind, np.subtract(list(r2.values()), list(r1.values())))\n",
    "plt.xticks(ind, list(r.keys()), rotation=\"vertical\")\n",
    "plt.ylim(-0.5, 0.5)\n",
    "plt.title(title)\n",
    "plt.ylabel(measure)\n",
    "plt.xlabel(\"topics\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a23733",
   "metadata": {},
   "source": [
    "Note: the y axis has been extended(zoomed in), original is (-1, 1), to make the graph more clear, it\n",
    "has been set to (-0.5, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af86c1d",
   "metadata": {},
   "source": [
    "When you have described and provided implementations for each method, include a table with statistical analysis here. \n",
    "\n",
    "For convenience, you can use tools like this one to make it easier: https://www.tablesgenerator.com/markdown_tables, or if you are using pandas, you can convert dataframes to markdown https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_markdown.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
