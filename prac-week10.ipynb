{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# INFS7410 Week 10 Practical\n",
    "\n",
    "##### version 1.3\n",
    "\n",
    "###### The INFS7410 Teaching Team\n",
    "\n",
    "##### Tutorial Etiquette:\n",
    "*Please refrain from loud noises, irrelevant conversations and use of mobile phones during practical activities. Be respectful of everyone's opinions and ideas during the practical activities. You will be asked to leave if you disturb. Remember the tutor is there to help you understand and learn, not to provide debugging of your code or solutions to assignments.*\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### About today's Practical\n",
    "In this week's practical, you will learn and implement a dense retriever called ANCE and a contextualized exact term matching method called TILDEv2. Unlike monoBERT, these methods can pre-compute document representation offline and only need to encode query representation during online inference, thus enjoy low query latency. However, since GPU is requried to encode the whole passage collection, in this practice we still compute document representations in an \"on-the-fly\" manner, just like what we did for monoBERT in the last practical. In your project, we will provide pre-computed passage representations for you to download.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Nearest Neighbor Search with ANCE\n",
    "\n",
    "ANCE is a typical dense retriever, which was proposed in the research [paper](https://arxiv.org/pdf/2007.00808.pdf) that pre-compute the document embeddings and compute the query embeddings on-the-fly, then use dot product to compute the similarities between query and documents. The model architecture shown in the leacture:![ANCE.png](ANCE.png)\n",
    "\n",
    "First, download the model from this [link](https://drive.google.com/file/d/1rbi-C6Ku5p1fG0ivL7cE3zunxzk60usA/view?usp=sharing), unzip it and put it in the same folder as this notebook, then run the following cell to initialize the model and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import AnceModel\n",
    "from transformers import AutoTokenizer\n",
    "device = 'cpu'\n",
    "ance_model = AnceModel.from_pretrained('ANCE_Model').eval()\n",
    "ance_model.to(device)\n",
    "ance_tokenizer = AutoTokenizer.from_pretrained('ANCE_Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use ANCE model to compute the embeddings of the query \"what is priority pass\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.14771283e+00  2.84968227e-01 -6.51907682e-01  3.53783146e-02\n",
      " -4.06788290e-01 -5.92642009e-01  1.45296276e+00  4.34321091e-02\n",
      "  1.87019634e+00  5.45588970e-01  4.63530093e-01  1.34180403e+00\n",
      "  1.18982032e-01 -1.52603483e+00 -2.41587698e-01 -2.20729017e+00\n",
      "  1.03682518e+00  2.32850671e-01 -8.05468932e-02 -9.90941346e-01\n",
      " -4.33072895e-01  8.97244215e-01 -5.80886245e-01 -6.69079125e-01\n",
      "  7.66609907e-01 -4.21835512e-01 -1.94484517e-02 -8.76279056e-01\n",
      "  1.16014814e+00  6.31652176e-01 -2.08898067e-01 -1.25032341e+00\n",
      "  1.07165284e-01  5.60523927e-01  1.26234651e+00 -1.81427896e+00\n",
      "  3.76601785e-01 -1.95675898e+00  2.46329337e-01  7.16556132e-01\n",
      "  8.58545229e-02  7.42675781e-01 -1.56575203e+00  4.38455269e-02\n",
      "  8.25252056e-01  1.64467371e+00 -2.11803341e+00 -1.18672204e+00\n",
      " -2.99669236e-01 -4.55030590e-01  6.03962615e-02  1.31918323e+00\n",
      " -1.39826381e+00 -1.63742101e+00 -2.34666601e-01 -2.26846266e+00\n",
      " -3.45829457e-01 -4.09893811e-01 -8.11094940e-01  1.45112848e+00\n",
      " -1.34125590e+00  8.86524618e-01 -1.48841250e+00  2.88261235e-01\n",
      "  1.47676617e-01  1.17302036e+00  2.30843619e-01  1.13612270e+00\n",
      "  2.32545093e-01  4.46675032e-01  7.95272052e-01 -4.87449139e-01\n",
      " -7.22434461e-01  1.24866819e+00 -4.02335264e-02 -2.37464413e-01\n",
      "  1.36765587e+00  7.98379600e-01 -5.75301886e-01 -8.42464328e-01\n",
      " -6.93943143e-01 -4.07160968e-01  7.95807838e-01  3.51295978e-01\n",
      "  8.11606944e-01 -1.58165503e+00  1.29284418e+00  1.19751379e-01\n",
      " -6.18819855e-02  1.35496244e-01 -1.39379454e+00  7.05240846e-01\n",
      " -1.28735676e-01 -1.47356108e-01  4.67972010e-01 -5.55994093e-01\n",
      "  3.39696288e-01  2.35846853e+00  5.58493972e-01  4.90005612e-01\n",
      "  2.03234747e-01 -1.28845716e+00  9.15133476e-01 -1.01945984e+00\n",
      " -5.00137508e-01 -5.43617010e-01 -8.08926299e-03  4.99319047e-01\n",
      "  7.55785108e-01 -1.27134129e-01 -8.22301328e-01  4.51326638e-01\n",
      "  2.65580148e-01 -1.48074314e-01  8.59104037e-01  8.40945542e-01\n",
      " -1.31949115e+00  1.06466675e+00 -2.43742727e-02 -1.35346985e+00\n",
      "  6.68599606e-01  1.78004112e-02 -5.36335647e-01  1.46595550e+00\n",
      "  9.24883723e-01 -5.14860570e-01  1.21592984e-01  1.76932633e+00\n",
      " -9.13297832e-01  1.17564529e-01 -1.29217446e+00  6.35556936e-01\n",
      "  4.27980602e-01 -2.55275249e-01 -1.14462888e+00  3.68027896e-01\n",
      " -2.87381470e-01 -1.25934339e+00 -2.22205490e-01  1.19443107e+00\n",
      " -1.21160316e+00 -1.71719766e+00 -6.50644064e-01 -1.42159596e-01\n",
      "  5.44238612e-02 -2.89688945e-01 -1.07196164e+00  1.87344417e-01\n",
      "  1.81881201e+00 -1.07203506e-01  9.49460566e-01  1.57188010e+00\n",
      "  6.38825595e-01 -3.70246232e-01 -3.92922878e-01 -2.23478228e-01\n",
      "  1.04145837e+00  9.68365729e-01  2.39448118e+00  1.37329698e+00\n",
      " -1.48048437e+00 -6.14235818e-01  4.05934572e-01  1.92792907e-01\n",
      " -2.09696628e-02 -1.44456971e+00 -3.83425504e-01  1.75826764e+00\n",
      " -1.96117193e-01  9.02104735e-01 -1.20704722e+00 -8.45440507e-01\n",
      "  1.96709514e+00  8.58106852e-01  1.93299925e+00 -3.10337096e-01\n",
      "  9.90373492e-01 -1.38339311e-01 -4.81321186e-01  1.34381676e+00\n",
      "  6.47013724e-01 -6.05339646e-01  9.96483207e-01  5.48079550e-01\n",
      "  8.88499200e-01 -1.12452102e+00  1.14797366e+00  1.59433472e+00\n",
      "  6.91848934e-01  1.15162551e+00  1.16131103e+00  3.40881906e-02\n",
      "  6.93597436e-01  2.55510747e-01 -2.38239527e+00 -8.82392466e-01\n",
      "  1.98725164e-01 -1.05162203e+00 -8.01334023e-01  1.82744849e+00\n",
      " -7.81051397e-01 -1.11669981e+00 -6.26408279e-01  5.57497859e-01\n",
      "  1.16441214e+00 -4.72111642e-01  2.78750390e-01 -2.71670699e-01\n",
      "  7.57351935e-01 -1.33396184e+00 -6.00330532e-01  9.93447840e-01\n",
      "  2.80233884e+00 -5.55655122e-01 -9.96279776e-01 -6.73482716e-01\n",
      " -7.91916311e-01 -3.29999477e-01 -5.48199415e-01 -1.03084493e+00\n",
      "  5.31179681e-02  9.69459414e-01 -4.37581539e-01  1.73971784e+00\n",
      " -1.84819257e+00  6.08426221e-02  5.52321613e-01 -7.23841727e-01\n",
      "  1.40758467e+00  3.84913087e-01 -6.20458961e-01  5.03232360e-01\n",
      "  1.55473399e+00 -7.75790930e-01 -1.18240166e+00  3.24393362e-01\n",
      " -1.41769624e+00 -2.65511537e+00  5.09406269e-01 -9.14339721e-01\n",
      " -3.63666296e-01  1.20155907e+00  1.56641454e-02  4.25105453e-01\n",
      " -1.99668825e+00  6.20010257e-01 -2.47812405e-01 -1.39724970e+00\n",
      " -6.12171352e-01  4.41937119e-01  1.37950271e-01  2.00658512e+00\n",
      "  1.26737618e+00  1.73670495e+00  4.49685529e-02 -4.05325741e-01\n",
      " -3.84716272e-01  2.67052472e-01  6.57407820e-01  2.70065516e-01\n",
      " -1.16796660e+00  6.00379884e-01 -1.70913923e+00  9.37300742e-01\n",
      "  1.40206754e-01 -2.97299474e-01 -7.71579444e-02  5.36392093e-01\n",
      "  1.75662905e-01  1.38487136e-02 -1.36136031e+00 -1.07816958e+00\n",
      " -1.15310895e+00 -1.05031085e+00  6.48197085e-02 -8.66019487e-01\n",
      "  9.93777454e-01  1.47173572e+00  4.09675211e-01  2.98556775e-01\n",
      " -5.13533831e-01 -5.28344154e-01  9.48228896e-01  6.38497099e-02\n",
      " -8.83822739e-01 -6.26772225e-01  1.55977264e-01 -1.31603634e+00\n",
      " -6.83516979e-01 -7.25971818e-01  1.08622336e+00 -6.60935521e-01\n",
      "  1.13141239e+00  1.12969780e+00  2.55071223e-01 -1.49754870e+00\n",
      " -4.12817150e-01  3.00724566e-01 -5.70052326e-01 -7.94287324e-02\n",
      "  1.05061412e+00  1.35774136e+00 -3.65365654e-01  1.53566909e+00\n",
      "  1.49093711e+00 -1.08074158e-01  6.34795249e-01 -2.48838210e+00\n",
      "  4.31016445e-01 -1.28008187e+00 -1.14289665e+00 -6.96163356e-01\n",
      " -1.05601978e+00  1.59626877e+00 -4.91095454e-01  4.95567769e-01\n",
      "  1.38716686e+00  2.42347091e-01 -8.02887201e-01 -1.71040547e+00\n",
      " -5.99292934e-01 -1.69483542e+00  8.38501871e-01 -7.87409246e-01\n",
      "  9.09092128e-02  2.37538815e-02  4.43764538e-01  6.61413372e-01\n",
      " -1.34289265e+00  7.08999783e-02  1.52330184e+00 -9.19330865e-02\n",
      " -4.01367068e-01 -6.61580026e-01 -6.02084678e-04 -1.11658001e+00\n",
      "  9.68596637e-02 -4.03666794e-01 -9.83664393e-02  1.97281726e-02\n",
      "  3.81702483e-01 -1.30173469e+00 -7.67799854e-01  3.86141837e-01\n",
      "  1.44671679e+00 -2.24908412e-01  2.55414993e-01  7.53834248e-01\n",
      " -5.80648065e-01  7.80719101e-01 -1.25388455e+00 -1.94436267e-01\n",
      " -1.71495736e+00 -6.56102240e-01  4.49888587e-01  1.02926064e+00\n",
      "  1.73377752e+00 -7.62029529e-01  2.67903781e+00  1.89643413e-01\n",
      " -1.16332874e-01  1.75653505e+00 -1.41635883e+00  7.12450862e-01\n",
      "  3.72842640e-01  1.11501038e+00 -5.74236572e-01  6.40977085e-01\n",
      "  4.80309427e-01  3.00461501e-01 -1.52854788e+00 -3.57172698e-01\n",
      " -6.56005859e-01  1.60025382e+00  3.31786424e-01  2.56794393e-01\n",
      "  1.91034805e-02 -4.61735949e-02  2.76680607e-02  7.02643931e-01\n",
      " -1.12242460e+00 -1.30750287e+00 -1.03651416e+00 -2.50120968e-01\n",
      " -1.15914929e+00 -1.13650441e-01 -3.78632277e-01  1.95889827e-02\n",
      " -4.95510012e-01 -1.16956270e+00 -4.51882835e-03 -3.55411232e-01\n",
      "  7.80937001e-02  8.50958884e-01  9.28509355e-01  2.44048566e-01\n",
      "  1.66903627e+00  1.01802900e-01  8.18236887e-01 -7.50205934e-01\n",
      "  9.91065562e-01  9.97515857e-01  1.16815448e+00 -1.74403153e-02\n",
      "  2.40886167e-01 -6.62929654e-01  1.46859837e+00  1.59305990e+00\n",
      "  6.39898837e-01  9.32093620e-01 -7.32777655e-01 -1.40375882e-01\n",
      "  2.35640001e+00 -1.06998205e+00  3.83871384e-02 -9.86337900e-01\n",
      " -7.36898005e-01  3.20426673e-01 -1.73332560e+00 -1.62578225e-01\n",
      "  6.23627424e-01 -8.06592822e-01  4.12540942e-01 -4.73509580e-02\n",
      "  5.53498529e-02 -6.56210065e-01  2.49466106e-01 -4.12177831e-01\n",
      " -1.04218411e+00 -1.35590899e+00 -1.97669730e-01 -1.86550164e+00\n",
      "  7.94323623e-01 -1.34514368e+00  1.63209677e-01 -7.19016194e-02\n",
      " -1.62020361e+00  3.65000725e-01 -1.64108419e+00  8.41879129e-01\n",
      " -3.40214729e-01 -7.36780703e-01 -1.05501413e+00  1.93313301e-01\n",
      "  1.94467634e-01  9.13281202e-01  7.33827055e-01 -3.13122459e-02\n",
      "  1.40013486e-01  3.79321873e-01  2.33188167e-01  7.74146497e-01\n",
      "  1.31049752e+00 -1.28314865e+00  1.79527557e+00 -1.37526727e+00\n",
      " -1.16701162e+00 -5.27074225e-02 -1.18555832e+00 -2.33512425e+00\n",
      "  1.31317670e-03 -1.65832937e+00  1.90925866e-01  2.17005706e+00\n",
      " -7.08036199e-02  7.56323814e-01  8.90972555e-01  1.50322878e+00\n",
      " -1.01858068e+00 -9.96165395e-01  6.14390969e-01 -1.05704522e+00\n",
      "  1.02170420e+00  5.17840445e-01  1.40682364e+00 -6.59133017e-01\n",
      "  1.10041380e+00  2.73708738e-02 -1.26402140e-01  2.83313572e-01\n",
      "  9.07267451e-01 -1.10472120e-01  1.34891063e-01  4.67688870e-03\n",
      " -2.33546011e-02  3.65399808e-01 -1.28827000e+00 -1.85829699e+00\n",
      " -3.92656028e-01 -1.68305528e+00  2.03290439e+00  3.37173522e-01\n",
      " -2.02065802e+00 -1.18040860e+00  1.39252472e+00  1.00610542e+00\n",
      " -4.44790542e-01  6.43140316e-01  4.16443467e-01 -1.49376309e+00\n",
      " -1.61476359e-01 -9.25326169e-01 -1.55744910e+00 -5.03325522e-01\n",
      " -1.12050104e+00 -6.06395006e-01 -1.82971275e+00  1.74589068e-01\n",
      "  1.07170606e+00 -7.82239020e-01  7.58647025e-01  3.06641430e-01\n",
      "  4.79082078e-01 -1.34635329e+00  5.59690535e-01  1.21833004e-01\n",
      " -4.53083605e-01  1.93551385e+00  1.42582023e+00  1.80517995e+00\n",
      " -3.09891403e-01  6.27502143e-01 -1.74292433e+00 -1.06136370e+00\n",
      " -1.24949670e+00 -1.38979006e+00 -1.75936615e+00 -7.34988749e-01\n",
      " -1.13149369e+00  5.43706000e-01 -6.08036995e-01 -2.95412809e-01\n",
      " -8.66288781e-01 -2.57773042e-01  8.22378173e-02  8.23950529e-01\n",
      " -3.00061315e-01  9.77460504e-01  3.37219566e-01 -1.80835772e+00\n",
      " -1.70361325e-01  3.01250041e-01  9.65921700e-01  1.38337374e+00\n",
      "  6.39994889e-02 -8.82953644e-01  7.46598661e-01  8.89930367e-01\n",
      "  4.22584981e-01 -1.38414466e+00  1.17858875e+00  4.04351175e-01\n",
      " -6.27613068e-01 -1.83655882e+00 -1.39388001e+00 -1.13400340e+00\n",
      " -1.13412738e+00  2.30392146e+00 -1.37586939e+00 -8.62409294e-01\n",
      "  7.64823079e-01 -4.35387909e-01  8.11210036e-01  6.38996780e-01\n",
      " -3.40329826e-01  1.03781843e+00 -6.15616143e-01  4.37768877e-01\n",
      "  1.37754500e+00  1.69140160e+00  3.54482800e-01  3.94755781e-01\n",
      "  7.78605163e-01 -2.62692750e-01 -7.16469228e-01  7.38873839e-01\n",
      "  1.95032394e+00 -1.63884629e-02 -1.16991937e+00  1.34611607e+00\n",
      "  1.48018539e-01 -5.36746502e-01  1.54704070e+00  3.61634612e-01\n",
      " -1.30642653e+00  3.97620440e-01 -6.81774676e-01  2.14456630e+00\n",
      " -9.44112986e-03 -7.92984962e-01 -9.86883882e-03 -1.53217769e+00\n",
      " -5.53891480e-01  5.31234682e-01 -4.81260493e-02  1.24280298e+00\n",
      " -4.71309394e-01 -9.55546200e-01  6.43479466e-01 -3.41254915e-03\n",
      " -5.44729829e-01 -6.30325973e-02 -1.46619940e+00  9.79302287e-01\n",
      "  3.70221257e-01 -4.24203545e-01 -8.29575539e-01 -2.98217624e-01\n",
      "  6.65787399e-01 -1.19211817e+00 -7.30346203e-01  1.27908862e+00\n",
      " -3.26913595e-01  1.19979572e+00 -5.00689745e-01 -3.35869566e-02\n",
      " -4.48878258e-01  1.71320271e+00  9.00127709e-01  9.15602028e-01\n",
      " -6.29718184e-01 -5.71916521e-01  1.59138525e+00 -6.47866189e-01\n",
      "  5.66343904e-01 -6.09944016e-02  2.40617728e+00 -1.00793326e+00\n",
      " -3.84302884e-01  2.79732406e-01  6.88313484e-01  6.10193551e-01\n",
      "  1.99837044e-01  1.30184007e+00  2.80595511e-01 -3.85234058e-01\n",
      " -1.23182774e+00  1.07202888e+00  9.62730199e-02 -8.78226042e-01\n",
      " -2.29634866e-01 -4.87066418e-01 -5.64708233e-01  3.70193034e-01\n",
      " -8.64103019e-01  5.71061611e-01  3.06318760e-01  8.63939345e-01\n",
      "  2.02168274e+00 -1.41773796e+00 -3.76974314e-01 -1.12080705e+00\n",
      " -1.60280049e+00  1.24859107e+00  8.14391971e-01  5.20682573e-01\n",
      "  8.61252069e-01  8.74541283e-01 -6.79387212e-01  6.60751045e-01\n",
      "  1.21377838e+00  4.86541465e-02 -6.16499819e-02  1.03157532e+00\n",
      " -1.03082621e+00  1.37401032e+00 -3.28609422e-02  3.87901247e-01\n",
      "  2.07865357e-01  2.48567783e-03 -1.82354838e-01 -3.39906573e-01\n",
      "  9.34371293e-01 -4.39281970e-01 -6.45631790e-01 -1.28338665e-01\n",
      "  6.94503427e-01  6.31571829e-01 -1.13664150e+00 -3.87504809e-02\n",
      "  9.36165154e-02 -4.33895856e-01 -3.74401748e-01  1.72831729e-01\n",
      " -1.41082390e-03  1.68953049e+00  2.11654752e-01 -1.29991388e+00\n",
      " -1.33550084e+00  5.83089352e-01 -1.14301062e+00  9.22806382e-01\n",
      " -1.78825259e+00 -9.10664856e-01  2.26077437e-01 -1.64925063e+00\n",
      " -7.66800106e-01  1.20009482e-01 -3.38131189e-01  9.61674392e-01\n",
      "  4.25426275e-01 -1.82360637e+00  2.13056159e+00  1.06055427e+00\n",
      "  1.09069303e-01 -5.29467225e-01  1.71780026e+00 -3.70084792e-01\n",
      " -1.77912962e+00 -9.23658609e-01  3.78797352e-02  9.57916975e-01\n",
      " -7.39793658e-01  6.21010721e-01  5.31048119e-01 -1.41895783e+00\n",
      " -1.79221302e-01  7.33476341e-01  1.55585885e-01 -4.20740753e-01\n",
      " -7.69309878e-01  2.24866197e-01  8.08085263e-01 -1.59254313e+00\n",
      " -3.25399756e-01 -6.95312500e-01 -1.90746200e+00 -1.52090609e-01\n",
      " -1.30277145e+00 -3.60360652e-01 -4.84320015e-01  1.17874062e+00\n",
      "  8.86944532e-01 -1.33227623e+00  1.57172012e+00  1.90999532e+00\n",
      "  1.43837106e+00  7.34557152e-01 -1.01969910e+00  4.32888329e-01\n",
      " -5.73148310e-01  1.17409575e+00  7.93110549e-01  7.94685543e-01\n",
      " -6.23327553e-01  8.09091985e-01  3.60354707e-02  5.58954179e-01\n",
      "  8.00297558e-01 -6.83064699e-01 -9.05806363e-01 -1.16783953e+00\n",
      "  1.64878213e+00  1.28627253e+00 -1.30473399e+00  7.28991687e-01\n",
      "  1.10336554e+00  7.30843544e-01  3.79515588e-02 -3.27847779e-01\n",
      " -2.66499251e-01  9.16427433e-01 -7.46608853e-01 -5.87191164e-01\n",
      "  9.07357275e-01 -7.37971723e-01  1.02220404e+00 -1.16122925e+00]\n"
     ]
    }
   ],
   "source": [
    "query = 'what is priority pass'\n",
    "inputs = ance_tokenizer(\n",
    "            [query],\n",
    "            max_length=64,\n",
    "            padding='longest',\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "query_embeddings = ance_model(inputs[\"input_ids\"]).detach().cpu().numpy().flatten()\n",
    "print(query_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the query embeddings, we move to compute two passage embeddings, passage 1 is highly relevant, and passage 2 is not related to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "passage_1 = 'Priority Pass is the world’s leading airport lounge access programme, providing an airport lounge for wherever your travel takes you, regardless of your class of travel or airline flown.'\n",
    "passage_2 = 'Sea World and SeaWorld both keep animals in cramped and unnatural enclosures, and they both force dolphins to participate in shows and breeding programmes.'\n",
    "passage1_inputs = ance_tokenizer(\n",
    "            [passage_1],\n",
    "            max_length=512,\n",
    "            padding='longest',\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "passage2_inputs = ance_tokenizer(\n",
    "            [passage_2],\n",
    "            max_length=512,\n",
    "            padding='longest',\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "passage1_inputs.to(device)\n",
    "passage2_inputs.to(device)\n",
    "passage1_embeddings = ance_model(passage1_inputs[\"input_ids\"]).detach().cpu().numpy().flatten()\n",
    "passage2_embeddings = ance_model(passage2_inputs[\"input_ids\"]).detach().cpu().numpy().flatten()\n",
    "print(passage1_embeddings.shape)\n",
    "print(passage2_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the query embeddings and two passage embeddings, we can use dot product to calculate the similarities between the query and the two passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713.283\n",
      "697.2628\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "score_1 = np.dot(query_embeddings, passage1_embeddings)\n",
    "score_2 = np.dot(query_embeddings, passage2_embeddings)\n",
    "print(score_1)\n",
    "print(score_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: build a two-stage ranking pipeline with BM25 + ANCE\n",
    "We provide the following function `ance_encode` for you to compute the embedding (vector) for a given piece of text.  Similar to last week exercise where you have built a ranking pipeline with BM25 + monoBERT, you can use pyserini build-in SimpleSearcher function to perform BM25 retrieval and use hits.raw() to get document text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ance_encode(text, device='cpu'):\n",
    "    # get query inputs\n",
    "    inputs = ance_tokenizer(\n",
    "            [text],\n",
    "            max_length=64,\n",
    "            padding='longest',\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "    # pass query inputs to device and to model\n",
    "    # use 'cuda:0' if you are using GPU\n",
    "    inputs.to(device)\n",
    "    # compute query embeddings\n",
    "    embeddings = ance_model(inputs[\"input_ids\"]).detach().cpu().numpy().flatten()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 8636705 {\n",
      "  \"id\" : \"8636705\",\n",
      "  \"contents\" : \"Priority Pass Coupons. The 4 most popular Priority Pass coupons & PriorityPass promo codes for March 2017. Priority Pass provides airport VIP lounge access irrespective of who you are flying with, what class you are traveling in, or whether you belong to an airline lounge program.\"\n",
      "}\n",
      "2 8636699 {\n",
      "  \"id\" : \"8636699\",\n",
      "  \"contents\" : \"Priority Pass Coupons. Rated 4.5 from 88 votes. The 4 most popular Priority Pass coupons & PriorityPass promo codes for March 2017. Priority Pass provides airport VIP lounge access irrespective of who you are flying with, what class you are traveling in, or whether you belong to an airline lounge program.\"\n",
      "}\n",
      "3 8636702 {\n",
      "  \"id\" : \"8636702\",\n",
      "  \"contents\" : \"Priority Pass Promo Codes. There are 10 priority pass coupon codes, coupons, discounts for you to consider including 10 prioritypass.com promo codes and 0 deals in April 2017. Priority Pass is the worldâs largest independent airport lounge access program.\"\n",
      "}\n",
      "4 8636698 {\n",
      "  \"id\" : \"8636698\",\n",
      "  \"contents\" : \"Priority PassJoin Priority Pass And Gain Access To Over 900 Airport Lounges Join Priority Pass And Gain Access To Over 900 Airport Lounges 201 used this deal. Details: No promo code required. Click Get the deal to be taken to this offer on Priority Pass. Exclusions may apply. More.\"\n",
      "}\n",
      "5 8242370 {\n",
      "  \"id\" : \"8242370\",\n",
      "  \"contents\" : \"Activating Chase Sapphire Reserve Priority Pass. On this card benefits screen you will see a number of benefits including your Priority Pass Select lounge membership, Global Entry fee credit and rental car benefits. To activate your Priority Pass Select Membership, simply click âActivate Nowâ.\"\n",
      "}\n",
      "(713.5188, '7807976')\n",
      "(711.54956, '8636704')\n",
      "(711.03357, '8636702')\n",
      "(710.9159, '7807975')\n",
      "(710.6179, '8636700')\n"
     ]
    }
   ],
   "source": [
    "from pyserini.search import SimpleSearcher\n",
    "from pyserini.analysis import Analyzer, get_lucene_analyzer\n",
    "from pyserini.index import IndexReader\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "searcher = SimpleSearcher('indexes/lucene-index-msmarco-passage-noProcessing/')\n",
    "searcher.set_analyzer(get_lucene_analyzer(stemming=False, stopwords=False))\n",
    "\n",
    "hits = searcher.search(query)\n",
    "for i in range(0, 5):\n",
    "    print(f'{i+1} {hits[i].docid} {hits[i].raw}')\n",
    "\n",
    "\n",
    "lucene_analyzer = get_lucene_analyzer(stemming=False, stopwords=False)\n",
    "analyzer = Analyzer(lucene_analyzer)\n",
    "searcher = SimpleSearcher('indexes/lucene-index-msmarco-passage-vectors-noProcessing/')\n",
    "searcher.set_analyzer(lucene_analyzer)\n",
    "\n",
    "index_reader = IndexReader('indexes/lucene-index-msmarco-passage-vectors-noProcessing/')\n",
    "\n",
    "def search(k: int=10):\n",
    "    hits = searcher.search(query, k=k)\n",
    "    q_terms = analyzer.analyze(query)\n",
    "    # print(q_terms)\n",
    "    result = []\n",
    "    for i, hit in enumerate(hits):\n",
    "        # Compute the statistics.\n",
    "        tf = index_reader.get_document_vector(hit.docid)\n",
    "        df= {term: (index_reader.get_term_counts(term, analyzer=None))[0] for term in tf.keys()}\n",
    "        doc_len = len(tf)\n",
    "        bm25_score = 0\n",
    "\n",
    "        c = list((Counter(q_terms) & Counter(tf.keys())).elements())\n",
    "\n",
    "        for term in c:\n",
    "            bm25_score += index_reader.compute_bm25_term_weight(hit.docid, term, analyzer=None)\n",
    "        content = json.loads(hit.raw)\n",
    "        result.append((content, bm25_score))\n",
    "    return result\n",
    "\n",
    "\n",
    "bm25 = search(k=50)\n",
    "bm25.sort(key=lambda x:x[1],reverse=True)\n",
    "\n",
    "\n",
    "query_embedding = ance_encode(query)\n",
    "\n",
    "result = []\n",
    "\n",
    "for i in bm25:\n",
    "    passage_embedding = ance_encode(i[0][\"contents\"])\n",
    "    score = np.dot(query_embedding, passage_embedding)\n",
    "    result.append((score, i[0][\"id\"]))\n",
    "    \n",
    "result.sort(key=lambda x:x[0], reverse=True)    \n",
    "\n",
    "j = 0\n",
    "\n",
    "for i in result:\n",
    "    if j == 5:\n",
    "        break\n",
    "    print(i)\n",
    "    j=j+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute contextualized term weights with TILDEv2\n",
    "\n",
    "Unlike dense retrievers, TILDEv2, which was proposed in our research [paper](https://arxiv.org/pdf/2108.08513.pdf) uses contextualized term weights to re-rank documents. Particularly, instead of traditional bag-of-words methods such as BM25 and TF-IDF, TILDEv2 exploits BERT to compute contextualized term weights, as shown in the as the model architecture shown in the leacture:![tildev2.png](tildev2.png) \n",
    "\n",
    "Documents then can be re-ranked by summing up the term weights that appeared in both query and document. Let's first check out how to use TILDEv2 to compute contextualized term weights.\n",
    "\n",
    "First, download the model from this [link](https://drive.google.com/file/d/1g7oA9EZqpnQDNn4Uwv7atsMMk1g3P-Im/view?usp=sharing), unzip it and put it in the same folder as this notebook, then run the following cell to initialize the model and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import TILDEv2\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model = TILDEv2.from_pretrained(\"tildev2-noexp\").eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tildev2-noexp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use TILDEv2 to compute contextualized term weights of the passage: \"Unlike cats, dogs are usually great exercise pals. Many breads enjoy running and hiking, and will happily trek along on any trip.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Unlike cats, dogs are usually great exercise pals. Many breads enjoy running and hiking, \\\n",
    "and will happily trek along on any trip.\"\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "token_ids, token_weights = model.encode(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will print out the term weights for each token in the passage. However, before you continue, there is something for you to think of:\n",
    "- If the scoring function is just term frequency. What would be the term weight for the term cats and dogs?\n",
    "- Which term should be more important in this passage, cats or dogs?\n",
    "\n",
    "Now lets run this following cell to print out contextualized term weights computed by TILDEv2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unlike: 3.254988431930542\n",
      "cats: 3.862273931503296\n",
      "dogs: 4.299813747406006\n",
      "usually: 1.7652360200881958\n",
      "great: 1.009302020072937\n",
      "exercise: 4.089148044586182\n",
      "pal: 7.571357250213623\n",
      "many: 0.0\n",
      "bread: 8.876324653625488\n",
      "enjoy: 3.8195455074310303\n",
      "running: 3.348376989364624\n",
      "hiking: 3.4978909492492676\n",
      "happily: 4.266161918640137\n",
      "trek: 3.4675521850585938\n",
      "along: 2.8126070499420166\n",
      "trip: 2.9206016063690186\n"
     ]
    }
   ],
   "source": [
    "for token_id, weight in zip(token_ids, token_weights):\n",
    "    print(f\"{tokenizer.decode(token_id)}: {weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe? dose the term weights make sense to you? We note TILDEv2 will remove some predefined stopwords and special tokens such as `and`. You can think TILDEv2 gives zero weight to those stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: build a two-stage ranking pipeline with BM25 + TILDEv2\n",
    "\n",
    "We provide the following function `tildev2_scoreing` for you to compute the relevance score give a query-document text pair. Similar to last week exercise where you have built a ranking pipeline with BM25 + monoBERT, you can use pyserini build-in SimpleSearcher function to perform BM25 retrieval and use hits.raw() to get document text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "stop_ids = model.get_stop_ids(tokenizer)\n",
    "\n",
    "def tildev2_scoreing(query, document):\n",
    "    # get document term weights\n",
    "    inputs = tokenizer(document, return_tensors='pt')\n",
    "    token_ids, token_weights = model.encode(**inputs)\n",
    "    token_ids = np.array(token_ids)\n",
    "    token_weights = np.array(token_weights)\n",
    "    \n",
    "    # get query token ids\n",
    "    query_ids = tokenizer(query, add_special_tokens=False)[\"input_ids\"]\n",
    "    query_ids = [tok_id for tok_id in query_ids if tok_id not in stop_ids]  # remove stopwords for query\n",
    "    \n",
    "    # use query token ids to match term weights in the document\n",
    "    token_idx = [np.where(token_ids == tok_id) for tok_id in query_ids]\n",
    "    score = 0\n",
    "    for idx in token_idx:\n",
    "        if len(idx[0]) != 0:\n",
    "            score += np.max(token_weights[idx])  # if a query term appears multiple times in the passage, use the max socre\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tildev2_scoreing(\"I like dogs\", text))\n",
    "print(tildev2_scoreing(\"I like cats\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 8636705 {\n",
      "  \"id\" : \"8636705\",\n",
      "  \"contents\" : \"Priority Pass Coupons. The 4 most popular Priority Pass coupons & PriorityPass promo codes for March 2017. Priority Pass provides airport VIP lounge access irrespective of who you are flying with, what class you are traveling in, or whether you belong to an airline lounge program.\"\n",
      "}\n",
      "2 8636699 {\n",
      "  \"id\" : \"8636699\",\n",
      "  \"contents\" : \"Priority Pass Coupons. Rated 4.5 from 88 votes. The 4 most popular Priority Pass coupons & PriorityPass promo codes for March 2017. Priority Pass provides airport VIP lounge access irrespective of who you are flying with, what class you are traveling in, or whether you belong to an airline lounge program.\"\n",
      "}\n",
      "3 8636702 {\n",
      "  \"id\" : \"8636702\",\n",
      "  \"contents\" : \"Priority Pass Promo Codes. There are 10 priority pass coupon codes, coupons, discounts for you to consider including 10 prioritypass.com promo codes and 0 deals in April 2017. Priority Pass is the worldâs largest independent airport lounge access program.\"\n",
      "}\n",
      "4 8636698 {\n",
      "  \"id\" : \"8636698\",\n",
      "  \"contents\" : \"Priority PassJoin Priority Pass And Gain Access To Over 900 Airport Lounges Join Priority Pass And Gain Access To Over 900 Airport Lounges 201 used this deal. Details: No promo code required. Click Get the deal to be taken to this offer on Priority Pass. Exclusions may apply. More.\"\n",
      "}\n",
      "5 8242370 {\n",
      "  \"id\" : \"8242370\",\n",
      "  \"contents\" : \"Activating Chase Sapphire Reserve Priority Pass. On this card benefits screen you will see a number of benefits including your Priority Pass Select lounge membership, Global Entry fee credit and rental car benefits. To activate your Priority Pass Select Membership, simply click âActivate Nowâ.\"\n",
      "}\n",
      "(18.761433601379395, '7807976')\n",
      "(16.786617279052734, '8636704')\n",
      "(16.344670295715332, '3255276')\n",
      "(16.268832206726074, '3255278')\n",
      "(16.23903465270996, '7807975')\n"
     ]
    }
   ],
   "source": [
    "from pyserini.search import SimpleSearcher\n",
    "from pyserini.analysis import Analyzer, get_lucene_analyzer\n",
    "from pyserini.index import IndexReader\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "searcher = SimpleSearcher('indexes/lucene-index-msmarco-passage-noProcessing/')\n",
    "searcher.set_analyzer(get_lucene_analyzer(stemming=False, stopwords=False))\n",
    "\n",
    "hits = searcher.search(query)\n",
    "for i in range(0, 5):\n",
    "    print(f'{i+1} {hits[i].docid} {hits[i].raw}')\n",
    "\n",
    "\n",
    "lucene_analyzer = get_lucene_analyzer(stemming=False, stopwords=False)\n",
    "analyzer = Analyzer(lucene_analyzer)\n",
    "searcher = SimpleSearcher('indexes/lucene-index-msmarco-passage-vectors-noProcessing/')\n",
    "searcher.set_analyzer(lucene_analyzer)\n",
    "\n",
    "index_reader = IndexReader('indexes/lucene-index-msmarco-passage-vectors-noProcessing/')\n",
    "\n",
    "def search(k: int=10):\n",
    "    hits = searcher.search(query, k=k)\n",
    "    q_terms = analyzer.analyze(query)\n",
    "    # print(q_terms)\n",
    "    result = []\n",
    "    for i, hit in enumerate(hits):\n",
    "        # Compute the statistics.\n",
    "        tf = index_reader.get_document_vector(hit.docid)\n",
    "        df= {term: (index_reader.get_term_counts(term, analyzer=None))[0] for term in tf.keys()}\n",
    "        doc_len = len(tf)\n",
    "        bm25_score = 0\n",
    "\n",
    "        c = list((Counter(q_terms) & Counter(tf.keys())).elements())\n",
    "\n",
    "        for term in c:\n",
    "            bm25_score += index_reader.compute_bm25_term_weight(hit.docid, term, analyzer=None)\n",
    "        content = json.loads(hit.raw)\n",
    "        result.append((content, bm25_score))\n",
    "    return result\n",
    "\n",
    "\n",
    "bm25 = search(k=50)\n",
    "bm25.sort(key=lambda x:x[1],reverse=True)\n",
    "\n",
    "result = []\n",
    "\n",
    "for i in bm25:\n",
    "    score = tildev2_scoreing(query, i[0][\"contents\"])\n",
    "    result.append((score, i[0][\"id\"]))\n",
    "    \n",
    "result.sort(key=lambda x:x[0], reverse=True)    \n",
    "\n",
    "\n",
    "j = 0\n",
    "\n",
    "for i in result:\n",
    "    if j == 5:\n",
    "        break\n",
    "    print(i)\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
